# PROPOSAL-2025-0004: Реализация анализа пиков событий в коде

## Диагностика
Код в `ratio_analyzer.py` в настоящее время не реализует методологию анализа пиков событий, описанную в `docs/FORMULAS.md` (v3.0). Отсутствует логика для идентификации пикового значения внутри каждого события-возможности и последующей категоризации этих пиков.

## Предлагаемое изменение
Модифицировать метод `finalize` в классе `StreamingRatioAnalyzer` (`ratio_analyzer.py`) для реализации анализа пиков событий.

1.  **Создать новый приватный метод `_analyze_event_peaks`**:
    *   Этот метод будет принимать на вход `deviation` и `threshold`.
    *   **Алгоритм**:
        1.  Создать булеву маску `is_above = np.abs(deviation) > threshold`.
        2.  Найти "острова" или "группы" последовательных `True` в этой маске. Это можно сделать, найдя разницу `np.diff` в маске, приведенной к `int`, и используя `np.where` для поиска начал и концов событий.
        3.  Для каждого "острова" (события) извлечь соответствующий срез из массива `deviation`.
        4.  Найти максимальное значение в этом срезе.
        5.  Собрать все найденные пики в список `event_peaks`.
        6.  Вернуть этот список.

2.  **Интегрировать в `finalize`**:
    *   Вызвать `_analyze_event_peaks` для получения списка пиков.
    *   На основе этого списка рассчитать новые метрики:
        *   `avg_event_peak_pct = np.mean(event_peaks)`
        *   `max_event_peak_pct = np.max(event_peaks)`
        *   `event_peak_distribution`: Рассчитать количество пиков, попадающих в корзины [0.3, 0.5), [0.5, 1.0), и >= 1.0.

3.  **Обновить возвращаемый словарь и `print_summary`**:
    *   Добавить все новые метрики (`avg_event_peak_pct`, `event_peak_distribution` и т.д.) в словарь, возвращаемый из `finalize`.
    *   Обновить функцию `print_summary`, чтобы она красиво отображала новую информацию, включая распределение пиков по категориям.

## Обоснование
Реализация этого предложения приведет код в полное соответствие с последней версией документации. Это позволит анализатору генерировать значительно более глубокие и полезные отчеты, оценивая не только частоту, но и "качество" торговых возможностей, что является ключевым для принятия торговых решений.

## Оценка рисков
- **Производительность**: Итерация по событиям для поиска пиков может быть вычислительно затратной на данных с очень большим количеством событий. Необходимо использовать векторизованные операции `numpy` везде, где это возможно, чтобы минимизировать падение производительности.
- **Сложность кода**: Метод `_analyze_event_peaks` будет самым сложным в классе. Он должен быть хорошо прокомментирован.

## План тестирования
1.  Создать небольшой тестовый массив `deviation` с 3-4 четко определенными событиями и известными пиками.
2.  Вызвать `_analyze_event_peaks` напрямую и убедиться, что он возвращает правильный список пиков.
3.  Запустить полный `ratio_analyzer.py` на тестовом CSV и проверить, что итоговый отчет в `print_summary` корректно отображает все новые метрики, включая распределение.

## План отката
`git checkout ratio_analyzer.py`