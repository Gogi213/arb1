# PROPOSAL-2025-0005: Оптимизация производительности анализа пиков событий

## Диагностика
Текущая реализация функции `_analyze_event_peaks` в `ratio_analyzer.py` использует цикл `for` в Python для итерации по каждому событию-возможности. На данных с большим количеством событий (сотни тысяч или миллионы) это приводит к значительному замедлению финального шага анализа, так как каждый вызов в цикле несет накладные расходы интерпретатора Python.

## Предлагаемое изменение
Полностью переписать функцию `_analyze_event_peaks`, заменив медленный цикл на одну векторизованную операцию с использованием `polars`.

**Новый алгоритм:**
1.  Обернуть входной массив `deviation` в `polars.DataFrame`.
2.  Добавить булеву колонку `is_above`, показывающую превышение порога.
3.  Добавить колонку `event_id` с помощью `is_above.rle_id()`. Эта функция эффективно нумерует непрерывные группы одинаковых значений, присваивая каждому "острову" событий уникальный ID.
4.  Отфильтровать все строки, не относящиеся к событиям (`is_above == False`).
5.  Сгруппировать `DataFrame` по `event_id`.
6.  Для каждой группы рассчитать максимальное значение отклонения с помощью агрегации `agg(pl.col('deviation').abs().max())`.
7.  Извлечь результат (список пиков) из полученного `DataFrame`.

## Обоснование
Этот подход переносит всю вычислительную нагрузку с медленного интерпретатора Python на высокооптимизированный движок `polars`, написанный на Rust. Операции выполняются векторизованно над целыми колонками данных, а не поэлементно. Это приведет к **кардинальному ускорению** (на порядки) функции `_analyze_event_peaks` и, как следствие, всего финального шага анализа, особенно на больших и "шумных" наборах данных.

## Оценка рисков
Риски отсутствуют. Изменение затрагивает только внутреннюю реализацию одной функции и не меняет ее ожидаемый результат или влияние на другие части программы. Результат вычислений будет идентичен, но получен значительно быстрее.

## План тестирования
1.  Создать тестовый массив `deviation` с известными пиками.
2.  Вызвать старую и новую версии `_analyze_event_peaks` на этом массиве и убедиться, что они возвращают идентичные списки пиков (с учетом возможной разной сортировки).
3.  (Опционально) Замерить время выполнения обеих функций на большом синтетическом наборе данных (например, 10 млн точек), чтобы подтвердить ускорение.

## План отката
`git checkout ratio_analyzer.py`