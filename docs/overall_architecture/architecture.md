# Высокоуровневая архитектура

Эта система предназначена для арбитражной торговли криптовалютами и состоит из трех основных компонентов: `collections`, `trader` и `analyzer`. Каждый компонент выполняет свою четко определенную роль и взаимодействует с другими через ясные контракты.

## Компоненты

### 1. `collections` (Сборщик данных)

- **Проект:** `SpreadAggregator` (C#)
- **Роль:** Является центральным хабом системы, ответственным за сбор, обработку и распространение рыночных данных.
- **Основные задачи:**
    - **Подключение к биржам:** Устанавливает соединения с несколькими криптовалютными биржами (Binance, Bybit, GateIo и др.) для получения данных в реальном времени.
    - **Сбор данных:** Подписывается на потоки тикеров (цены) и сделок.
    - **Распространение в реальном времени:** Запускает WebSocket-сервер, который транслирует полученные рыночные данные всем подключенным клиентам. Это основной источник данных для `trader`.
    - **Сохранение исторических данных:** Асинхронно записывает все полученные данные в структурированное хранилище (data lake) в формате Parquet. Эти файлы сохраняются в директорию `data/market_data` и служат источником данных для `analyzer`.
    - **Предоставление обогащенных данных:** Имеет REST API, который может считывать результаты анализа из `analyzer` для предоставления обогащенных данных, например, для UI.

### 2. `trader` (Торговый бот)

- **Проект:** `TraderBot` (C#)
- **Роль:** Ответственен за принятие торговых решений и исполнение сделок в реальном времени.
- **Основные задачи:**
    - **Получение данных:** Подключается к WebSocket-серверу, предоставляемому `collections`, для получения потока рыночных данных в реальном времени.
    - **Принятие решений:** На основе полученных данных `DecisionMaker` реализует торговую логику и определяет возможности для арбитража.
    - **Исполнение сделок:** Взаимодействует с API бирж для размещения и отмены ордеров.

### 3. `analyzer` (Анализатор)

- **Проект:** Python-скрипты
- **Роль:** Выполняет оффлайн-анализ исторических данных.
- **Основные задачи:**
    - **Чтение данных:** Обрабатывает Parquet-файлы из директории `data/market_data`, созданные `collections`.
    - **Анализ:** Проводит расчеты, выявляет статистические закономерности, тренды и другие метрики, которые не требуются в реальном времени.
    - **Сохранение результатов:** Записывает результаты своего анализа (например, в `analyzer/summary_stats`), которые затем могут быть использованы `collections`.

## Потоки данных и зависимости

```
+----------------+       (1) WebSocket        +----------+
|                | -------------------------> |          |
|  collections   |                            |  trader  |
| (C#/.NET)      | <------------------------- | (C#/.NET)|
|                |        (3) REST API        |          |
+-------+--------+       (Enriched Data)      +----------+
        |
        | (2) Parquet Files
        | (data/market_data)
        v
+-------+--------+
|                |
|   analyzer     |
|   (Python)     |
|                |
+----------------+
```

1.  **Real-Time Flow (`collections` -> `trader`):** `collections` непрерывно транслирует тикеры через WebSocket. `trader` подписывается на этот поток и немедленно реагирует на рыночные изменения.
2.  **Historical/Batch Flow (`collections` -> `analyzer`):** `collections` сохраняет все данные на диск. `analyzer` периодически или по запросу считывает эти данные для глубокого анализа.
3.  **Analysis Results Flow (`analyzer` -> `collections`):** `collections` может обращаться к результатам работы `analyzer`, чтобы обогатить данные, отдаваемые по своему REST API (например, для фронтенда или системы мониторинга).